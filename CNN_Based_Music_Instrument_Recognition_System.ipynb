{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0lFKPkrvPsJ",
        "outputId": "3d66352c-6e75-42f3-c008-bbfeccbe3504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y-0TCaqb4pdd",
        "outputId": "ee02c748-aae6-49cf-9784-53debb89b098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[STARTUP] Environment variables configured\n",
            "[STARTUP] Loading libraries (this may take 30-60 seconds)...\n",
            "[MEMORY] Configured 1 GPU(s) with memory growth\n",
            "[STARTUP] All libraries loaded successfully!\n",
            "\n",
            "======================================================================\n",
            "    CNN-BASED MUSIC INSTRUMENT RECOGNITION SYSTEM\n",
            "======================================================================\n",
            "\n",
            "[INIT] Initializing audio processor...\n",
            "[INIT] Audio processor ready\n",
            "\n",
            "[DATA] Loading training data from IRMAS dataset...\n",
            "[DATA] Dataset location: /content/drive/MyDrive/IRMAS-TrainingData\n",
            "[DATA] Scanning folder: tru\n",
            "[DATA]   Found 577 files for trumpet\n",
            "[DATA] Scanning folder: sax\n",
            "[DATA]   Found 626 files for saxophone\n",
            "[DATA] Scanning folder: voi\n",
            "[DATA]   Found 778 files for voice\n",
            "[DATA] Scanning folder: pia\n",
            "[DATA]   Found 721 files for piano\n",
            "[DATA] Scanning folder: vio\n",
            "[DATA]   Found 580 files for violin\n",
            "[DATA] Scanning folder: gel\n",
            "[DATA]   Found 760 files for electric_guitar\n",
            "[DATA] Scanning folder: cla\n",
            "[DATA]   Found 505 files for clarinet\n",
            "[DATA] Scanning folder: gac\n",
            "[DATA]   Found 637 files for acoustic_guitar\n",
            "[DATA] Scanning folder: org\n",
            "[DATA]   Found 682 files for organ\n",
            "[DATA] Scanning folder: flu\n",
            "[DATA]   Found 451 files for flute\n",
            "[DATA] Scanning folder: cel\n",
            "[DATA]   Found 388 files for cello\n",
            "\n",
            "[DATA] Discovered 11 unique instruments: ['acoustic_guitar', 'cello', 'clarinet', 'electric_guitar', 'flute', 'organ', 'piano', 'saxophone', 'trumpet', 'violin', 'voice']\n",
            "\n",
            "[DATA] Limiting to 200 files per instrument for optimal training...\n",
            "[DATA] Total files to process: 2200\n",
            "[DATA]   trumpet: 200 files\n",
            "[DATA]   saxophone: 200 files\n",
            "[DATA]   voice: 200 files\n",
            "[DATA]   piano: 200 files\n",
            "[DATA]   violin: 200 files\n",
            "[DATA]   electric_guitar: 200 files\n",
            "[DATA]   clarinet: 200 files\n",
            "[DATA]   acoustic_guitar: 200 files\n",
            "[DATA]   organ: 200 files\n",
            "[DATA]   flute: 200 files\n",
            "[DATA]   cello: 200 files\n",
            "\n",
            "[VISUALIZATION] Generating mel spectrograms for all instruments...\n",
            "[SAVE] Mel spectrograms saved to mel_spectrograms.png\n",
            "\n",
            "[FEATURES] Extracting multi-resolution features (this will take time)...\n",
            "[FEATURES] Processed 0/2200 files...\n",
            "Processed 50/2200 files (with augmentation: 100 samples)...\n",
            "[FEATURES] Processed 50/2200 files...\n",
            "Processed 100/2200 files (with augmentation: 200 samples)...\n",
            "[FEATURES] Processed 100/2200 files...\n",
            "Processed 150/2200 files (with augmentation: 300 samples)...\n",
            "[FEATURES] Processed 150/2200 files...\n",
            "Processed 200/2200 files (with augmentation: 400 samples)...\n",
            "[FEATURES] Processed 200/2200 files...\n",
            "Processed 250/2200 files (with augmentation: 500 samples)...\n",
            "[FEATURES] Processed 250/2200 files...\n",
            "Processed 300/2200 files (with augmentation: 600 samples)...\n",
            "[FEATURES] Processed 300/2200 files...\n",
            "Processed 350/2200 files (with augmentation: 700 samples)...\n",
            "[FEATURES] Processed 350/2200 files...\n",
            "Processed 400/2200 files (with augmentation: 800 samples)...\n",
            "[FEATURES] Processed 400/2200 files...\n",
            "Processed 450/2200 files (with augmentation: 900 samples)...\n",
            "[FEATURES] Processed 450/2200 files...\n",
            "Processed 500/2200 files (with augmentation: 1000 samples)...\n",
            "[FEATURES] Processed 500/2200 files...\n",
            "Processed 550/2200 files (with augmentation: 1100 samples)...\n",
            "[FEATURES] Processed 550/2200 files...\n",
            "Processed 600/2200 files (with augmentation: 1200 samples)...\n",
            "[FEATURES] Processed 600/2200 files...\n",
            "Processed 650/2200 files (with augmentation: 1300 samples)...\n",
            "[FEATURES] Processed 650/2200 files...\n",
            "Processed 700/2200 files (with augmentation: 1400 samples)...\n",
            "[FEATURES] Processed 700/2200 files...\n",
            "Processed 750/2200 files (with augmentation: 1500 samples)...\n",
            "[FEATURES] Processed 750/2200 files...\n",
            "Processed 800/2200 files (with augmentation: 1600 samples)...\n",
            "[FEATURES] Processed 800/2200 files...\n",
            "Processed 850/2200 files (with augmentation: 1700 samples)...\n",
            "[FEATURES] Processed 850/2200 files...\n",
            "Processed 900/2200 files (with augmentation: 1800 samples)...\n",
            "[FEATURES] Processed 900/2200 files...\n",
            "Processed 950/2200 files (with augmentation: 1900 samples)...\n",
            "[FEATURES] Processed 950/2200 files...\n",
            "Processed 1000/2200 files (with augmentation: 2000 samples)...\n",
            "[FEATURES] Processed 1000/2200 files...\n",
            "Processed 1050/2200 files (with augmentation: 2100 samples)...\n",
            "[FEATURES] Processed 1050/2200 files...\n",
            "Processed 1100/2200 files (with augmentation: 2200 samples)...\n",
            "[FEATURES] Processed 1100/2200 files...\n",
            "Processed 1150/2200 files (with augmentation: 2250 samples)...\n",
            "[FEATURES] Processed 1150/2200 files...\n",
            "Processed 1200/2200 files (with augmentation: 2300 samples)...\n",
            "[FEATURES] Processed 1200/2200 files...\n",
            "Processed 1250/2200 files (with augmentation: 2350 samples)...\n",
            "[FEATURES] Processed 1250/2200 files...\n",
            "Processed 1300/2200 files (with augmentation: 2400 samples)...\n",
            "[FEATURES] Processed 1300/2200 files...\n",
            "Processed 1350/2200 files (with augmentation: 2450 samples)...\n",
            "[FEATURES] Processed 1350/2200 files...\n",
            "Processed 1400/2200 files (with augmentation: 2500 samples)...\n",
            "[FEATURES] Processed 1400/2200 files...\n",
            "Processed 1450/2200 files (with augmentation: 2550 samples)...\n",
            "[FEATURES] Processed 1450/2200 files...\n",
            "Processed 1500/2200 files (with augmentation: 2600 samples)...\n",
            "[FEATURES] Processed 1500/2200 files...\n",
            "Processed 1550/2200 files (with augmentation: 2650 samples)...\n",
            "[FEATURES] Processed 1550/2200 files...\n",
            "Processed 1600/2200 files (with augmentation: 2700 samples)...\n",
            "[FEATURES] Processed 1600/2200 files...\n",
            "Processed 1650/2200 files (with augmentation: 2750 samples)...\n",
            "[FEATURES] Processed 1650/2200 files...\n",
            "Processed 1700/2200 files (with augmentation: 2800 samples)...\n",
            "[FEATURES] Processed 1700/2200 files...\n",
            "Processed 1750/2200 files (with augmentation: 2850 samples)...\n",
            "[FEATURES] Processed 1750/2200 files...\n",
            "Processed 1800/2200 files (with augmentation: 2900 samples)...\n",
            "[FEATURES] Processed 1800/2200 files...\n",
            "Processed 1850/2200 files (with augmentation: 2950 samples)...\n",
            "[FEATURES] Processed 1850/2200 files...\n",
            "Processed 1900/2200 files (with augmentation: 3000 samples)...\n",
            "[FEATURES] Processed 1900/2200 files...\n",
            "Processed 1950/2200 files (with augmentation: 3050 samples)...\n",
            "[FEATURES] Processed 1950/2200 files...\n",
            "Processed 2000/2200 files (with augmentation: 3100 samples)...\n",
            "[FEATURES] Processed 2000/2200 files...\n",
            "Processed 2050/2200 files (with augmentation: 3150 samples)...\n",
            "[FEATURES] Processed 2050/2200 files...\n",
            "Processed 2100/2200 files (with augmentation: 3200 samples)...\n",
            "[FEATURES] Processed 2100/2200 files...\n",
            "Processed 2150/2200 files (with augmentation: 3250 samples)...\n",
            "[FEATURES] Processed 2150/2200 files...\n",
            "Processed 2200/2200 files (with augmentation: 3300 samples)...\n",
            "\n",
            "[MEMORY] Garbage collection completed\n",
            "[DATA] Training with 11 instrument classes: ['acoustic_guitar', 'cello', 'clarinet', 'electric_guitar', 'flute', 'organ', 'piano', 'saxophone', 'trumpet', 'violin', 'voice']\n",
            "[DATA] Label shape after binarization: (3300, 11)\n",
            "Length of X: 3300\n",
            "Length of y: 3300\n",
            "Length of processed_files: 3300\n",
            "\n",
            "Training samples: 2640, Test samples: 660\n",
            "Training data shapes: [(2640, 64, 259, 1), (2640, 96, 259, 1), (2640, 128, 259, 1)]\n",
            "\n",
            "[MODEL] Creating CNN model for 11 instrument classes...\n",
            "\\nModel Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>,   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>,   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>,   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_average_p… │\n",
              "│                     │                   │            │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,827</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m259\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m259\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m259\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m259\u001b[0m,   │        \u001b[38;5;34m320\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m259\u001b[0m,   │        \u001b[38;5;34m320\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m259\u001b[0m,  │        \u001b[38;5;34m320\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m129\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m129\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m129\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m129\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m129\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m129\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_6[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m129\u001b[0m,   │     \u001b[38;5;34m18,496\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m129\u001b[0m,   │     \u001b[38;5;34m18,496\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m129\u001b[0m,   │     \u001b[38;5;34m18,496\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_7[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_5[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_8[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_average_p… │\n",
              "│                     │                   │            │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m197,120\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │      \u001b[38;5;34m2,827\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">609,291</span> (2.32 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m609,291\u001b[0m (2.32 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">609,291</span> (2.32 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m609,291\u001b[0m (2.32 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAINING] Starting training with enhanced regularization...\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 18ms/step - accuracy: 0.1253 - auc: 0.5317 - loss: 0.3898 - val_accuracy: 0.1303 - val_auc: 0.5916 - val_loss: 0.3653 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.1172 - auc: 0.5559 - loss: 0.3299 - val_accuracy: 0.1864 - val_auc: 0.6069 - val_loss: 0.3395 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.1654 - auc: 0.5839 - loss: 0.3177 - val_accuracy: 0.2909 - val_auc: 0.7347 - val_loss: 0.2986 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.2343 - auc: 0.7134 - loss: 0.2920 - val_accuracy: 0.2576 - val_auc: 0.7935 - val_loss: 0.2701 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.2635 - auc: 0.7563 - loss: 0.2789 - val_accuracy: 0.2697 - val_auc: 0.7926 - val_loss: 0.2700 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.2717 - auc: 0.7767 - loss: 0.2708 - val_accuracy: 0.3394 - val_auc: 0.8208 - val_loss: 0.2597 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.3032 - auc: 0.7902 - loss: 0.2643 - val_accuracy: 0.3576 - val_auc: 0.8344 - val_loss: 0.2521 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.3264 - auc: 0.8050 - loss: 0.2589 - val_accuracy: 0.3818 - val_auc: 0.8496 - val_loss: 0.2424 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.3433 - auc: 0.8136 - loss: 0.2541 - val_accuracy: 0.4121 - val_auc: 0.8610 - val_loss: 0.2347 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3681 - auc: 0.8263 - loss: 0.2478 - val_accuracy: 0.4182 - val_auc: 0.8650 - val_loss: 0.2323 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.4113 - auc: 0.8505 - loss: 0.2367 - val_accuracy: 0.4364 - val_auc: 0.8797 - val_loss: 0.2232 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.4020 - auc: 0.8558 - loss: 0.2354 - val_accuracy: 0.4561 - val_auc: 0.8848 - val_loss: 0.2193 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.4340 - auc: 0.8617 - loss: 0.2308 - val_accuracy: 0.4924 - val_auc: 0.8909 - val_loss: 0.2128 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.4448 - auc: 0.8679 - loss: 0.2279 - val_accuracy: 0.4879 - val_auc: 0.8976 - val_loss: 0.2085 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.4830 - auc: 0.8817 - loss: 0.2187 - val_accuracy: 0.5500 - val_auc: 0.9130 - val_loss: 0.1972 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.4935 - auc: 0.8959 - loss: 0.2098 - val_accuracy: 0.5712 - val_auc: 0.9250 - val_loss: 0.1889 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.5214 - auc: 0.9023 - loss: 0.2041 - val_accuracy: 0.5682 - val_auc: 0.9118 - val_loss: 0.1982 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.5502 - auc: 0.9082 - loss: 0.1991 - val_accuracy: 0.6106 - val_auc: 0.9347 - val_loss: 0.1772 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.5573 - auc: 0.9149 - loss: 0.1935 - val_accuracy: 0.5970 - val_auc: 0.9283 - val_loss: 0.1820 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.5535 - auc: 0.9165 - loss: 0.1933 - val_accuracy: 0.6076 - val_auc: 0.9392 - val_loss: 0.1713 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.5749 - auc: 0.9188 - loss: 0.1897 - val_accuracy: 0.6470 - val_auc: 0.9454 - val_loss: 0.1641 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6077 - auc: 0.9352 - loss: 0.1748 - val_accuracy: 0.6712 - val_auc: 0.9540 - val_loss: 0.1566 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6203 - auc: 0.9367 - loss: 0.1737 - val_accuracy: 0.6424 - val_auc: 0.9450 - val_loss: 0.1653 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6278 - auc: 0.9379 - loss: 0.1732 - val_accuracy: 0.6591 - val_auc: 0.9519 - val_loss: 0.1605 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6559 - auc: 0.9457 - loss: 0.1646 - val_accuracy: 0.6879 - val_auc: 0.9566 - val_loss: 0.1533 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6532 - auc: 0.9425 - loss: 0.1668 - val_accuracy: 0.6000 - val_auc: 0.9302 - val_loss: 0.1773 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6548 - auc: 0.9431 - loss: 0.1666 - val_accuracy: 0.7091 - val_auc: 0.9599 - val_loss: 0.1471 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6804 - auc: 0.9493 - loss: 0.1584 - val_accuracy: 0.6939 - val_auc: 0.9570 - val_loss: 0.1473 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6649 - auc: 0.9526 - loss: 0.1571 - val_accuracy: 0.7197 - val_auc: 0.9623 - val_loss: 0.1398 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6929 - auc: 0.9536 - loss: 0.1533 - val_accuracy: 0.7000 - val_auc: 0.9598 - val_loss: 0.1434 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6930 - auc: 0.9567 - loss: 0.1512 - val_accuracy: 0.7333 - val_auc: 0.9690 - val_loss: 0.1335 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7066 - auc: 0.9599 - loss: 0.1474 - val_accuracy: 0.7424 - val_auc: 0.9662 - val_loss: 0.1371 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6904 - auc: 0.9602 - loss: 0.1461 - val_accuracy: 0.7288 - val_auc: 0.9661 - val_loss: 0.1359 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7185 - auc: 0.9632 - loss: 0.1402 - val_accuracy: 0.7439 - val_auc: 0.9704 - val_loss: 0.1297 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7085 - auc: 0.9622 - loss: 0.1421 - val_accuracy: 0.7258 - val_auc: 0.9660 - val_loss: 0.1373 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7272 - auc: 0.9660 - loss: 0.1393 - val_accuracy: 0.7394 - val_auc: 0.9699 - val_loss: 0.1297 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7354 - auc: 0.9654 - loss: 0.1368 - val_accuracy: 0.7424 - val_auc: 0.9655 - val_loss: 0.1356 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7284 - auc: 0.9672 - loss: 0.1362 - val_accuracy: 0.7803 - val_auc: 0.9727 - val_loss: 0.1251 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7632 - auc: 0.9708 - loss: 0.1264 - val_accuracy: 0.7712 - val_auc: 0.9730 - val_loss: 0.1238 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7509 - auc: 0.9724 - loss: 0.1284 - val_accuracy: 0.7515 - val_auc: 0.9667 - val_loss: 0.1337 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7775 - auc: 0.9769 - loss: 0.1205 - val_accuracy: 0.7848 - val_auc: 0.9774 - val_loss: 0.1166 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7765 - auc: 0.9724 - loss: 0.1244 - val_accuracy: 0.7545 - val_auc: 0.9759 - val_loss: 0.1239 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7572 - auc: 0.9735 - loss: 0.1251 - val_accuracy: 0.8091 - val_auc: 0.9768 - val_loss: 0.1132 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7969 - auc: 0.9789 - loss: 0.1151 - val_accuracy: 0.7561 - val_auc: 0.9743 - val_loss: 0.1268 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7806 - auc: 0.9780 - loss: 0.1176 - val_accuracy: 0.8076 - val_auc: 0.9826 - val_loss: 0.1054 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7956 - auc: 0.9788 - loss: 0.1157 - val_accuracy: 0.7773 - val_auc: 0.9786 - val_loss: 0.1162 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7930 - auc: 0.9748 - loss: 0.1197 - val_accuracy: 0.7985 - val_auc: 0.9808 - val_loss: 0.1102 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7929 - auc: 0.9804 - loss: 0.1124 - val_accuracy: 0.7955 - val_auc: 0.9791 - val_loss: 0.1123 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8019 - auc: 0.9807 - loss: 0.1126 - val_accuracy: 0.7939 - val_auc: 0.9815 - val_loss: 0.1088 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8140 - auc: 0.9840 - loss: 0.1056 - val_accuracy: 0.8227 - val_auc: 0.9839 - val_loss: 0.1025 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8118 - auc: 0.9816 - loss: 0.1086 - val_accuracy: 0.8379 - val_auc: 0.9827 - val_loss: 0.0994 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8115 - auc: 0.9833 - loss: 0.1035 - val_accuracy: 0.8242 - val_auc: 0.9819 - val_loss: 0.1031 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8272 - auc: 0.9819 - loss: 0.1029 - val_accuracy: 0.8212 - val_auc: 0.9803 - val_loss: 0.1064 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8240 - auc: 0.9834 - loss: 0.1047 - val_accuracy: 0.8288 - val_auc: 0.9816 - val_loss: 0.1008 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8383 - auc: 0.9852 - loss: 0.0993 - val_accuracy: 0.8121 - val_auc: 0.9814 - val_loss: 0.1072 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8366 - auc: 0.9860 - loss: 0.0977 - val_accuracy: 0.8242 - val_auc: 0.9839 - val_loss: 0.1016 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8410 - auc: 0.9874 - loss: 0.0958 - val_accuracy: 0.8303 - val_auc: 0.9824 - val_loss: 0.0994 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8328 - auc: 0.9844 - loss: 0.1003 - val_accuracy: 0.8500 - val_auc: 0.9848 - val_loss: 0.0948 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8442 - auc: 0.9880 - loss: 0.0939 - val_accuracy: 0.8212 - val_auc: 0.9810 - val_loss: 0.1067 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8508 - auc: 0.9865 - loss: 0.0954 - val_accuracy: 0.8318 - val_auc: 0.9826 - val_loss: 0.1044 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8284 - auc: 0.9844 - loss: 0.1003 - val_accuracy: 0.8318 - val_auc: 0.9849 - val_loss: 0.0998 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8521 - auc: 0.9859 - loss: 0.0944 - val_accuracy: 0.8485 - val_auc: 0.9870 - val_loss: 0.0923 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8525 - auc: 0.9889 - loss: 0.0913 - val_accuracy: 0.8576 - val_auc: 0.9849 - val_loss: 0.0942 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8599 - auc: 0.9876 - loss: 0.0919 - val_accuracy: 0.8106 - val_auc: 0.9797 - val_loss: 0.1097 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8475 - auc: 0.9863 - loss: 0.0947 - val_accuracy: 0.8258 - val_auc: 0.9787 - val_loss: 0.1096 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8653 - auc: 0.9912 - loss: 0.0841 - val_accuracy: 0.8409 - val_auc: 0.9857 - val_loss: 0.0941 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8792 - auc: 0.9882 - loss: 0.0847 - val_accuracy: 0.8591 - val_auc: 0.9850 - val_loss: 0.0956 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8676 - auc: 0.9885 - loss: 0.0887 - val_accuracy: 0.8364 - val_auc: 0.9823 - val_loss: 0.1003 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8714 - auc: 0.9907 - loss: 0.0852 - val_accuracy: 0.8561 - val_auc: 0.9835 - val_loss: 0.0953 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m658/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8797 - auc: 0.9907 - loss: 0.0809\n",
            "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8796 - auc: 0.9907 - loss: 0.0809 - val_accuracy: 0.8455 - val_auc: 0.9825 - val_loss: 0.0958 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8854 - auc: 0.9917 - loss: 0.0781 - val_accuracy: 0.8606 - val_auc: 0.9850 - val_loss: 0.0888 - learning_rate: 2.5000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9010 - auc: 0.9949 - loss: 0.0693 - val_accuracy: 0.8652 - val_auc: 0.9868 - val_loss: 0.0874 - learning_rate: 2.5000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9005 - auc: 0.9948 - loss: 0.0707 - val_accuracy: 0.8606 - val_auc: 0.9839 - val_loss: 0.0899 - learning_rate: 2.5000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8965 - auc: 0.9942 - loss: 0.0724 - val_accuracy: 0.8545 - val_auc: 0.9870 - val_loss: 0.0890 - learning_rate: 2.5000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9195 - auc: 0.9961 - loss: 0.0617 - val_accuracy: 0.8712 - val_auc: 0.9883 - val_loss: 0.0797 - learning_rate: 2.5000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9122 - auc: 0.9952 - loss: 0.0660 - val_accuracy: 0.8712 - val_auc: 0.9879 - val_loss: 0.0830 - learning_rate: 2.5000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9191 - auc: 0.9952 - loss: 0.0641 - val_accuracy: 0.8939 - val_auc: 0.9891 - val_loss: 0.0760 - learning_rate: 2.5000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9112 - auc: 0.9950 - loss: 0.0649 - val_accuracy: 0.8758 - val_auc: 0.9878 - val_loss: 0.0793 - learning_rate: 2.5000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9230 - auc: 0.9956 - loss: 0.0633 - val_accuracy: 0.8818 - val_auc: 0.9845 - val_loss: 0.0801 - learning_rate: 2.5000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9176 - auc: 0.9950 - loss: 0.0630 - val_accuracy: 0.8788 - val_auc: 0.9866 - val_loss: 0.0806 - learning_rate: 2.5000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9220 - auc: 0.9952 - loss: 0.0619 - val_accuracy: 0.8924 - val_auc: 0.9882 - val_loss: 0.0769 - learning_rate: 2.5000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9229 - auc: 0.9950 - loss: 0.0638 - val_accuracy: 0.8697 - val_auc: 0.9878 - val_loss: 0.0795 - learning_rate: 2.5000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9237 - auc: 0.9968 - loss: 0.0584 - val_accuracy: 0.8894 - val_auc: 0.9896 - val_loss: 0.0786 - learning_rate: 2.5000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9169 - auc: 0.9957 - loss: 0.0622 - val_accuracy: 0.8955 - val_auc: 0.9877 - val_loss: 0.0758 - learning_rate: 2.5000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9298 - auc: 0.9970 - loss: 0.0562 - val_accuracy: 0.8773 - val_auc: 0.9885 - val_loss: 0.0794 - learning_rate: 2.5000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9297 - auc: 0.9959 - loss: 0.0589 - val_accuracy: 0.8818 - val_auc: 0.9872 - val_loss: 0.0804 - learning_rate: 2.5000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9227 - auc: 0.9962 - loss: 0.0586 - val_accuracy: 0.8894 - val_auc: 0.9892 - val_loss: 0.0777 - learning_rate: 2.5000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9255 - auc: 0.9942 - loss: 0.0610 - val_accuracy: 0.8818 - val_auc: 0.9825 - val_loss: 0.0886 - learning_rate: 2.5000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9319 - auc: 0.9942 - loss: 0.0574 - val_accuracy: 0.8576 - val_auc: 0.9849 - val_loss: 0.0879 - learning_rate: 2.5000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9159 - auc: 0.9961 - loss: 0.0590 - val_accuracy: 0.8833 - val_auc: 0.9891 - val_loss: 0.0799 - learning_rate: 2.5000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9314 - auc: 0.9971 - loss: 0.0529 - val_accuracy: 0.8727 - val_auc: 0.9874 - val_loss: 0.0842 - learning_rate: 2.5000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m659/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9304 - auc: 0.9963 - loss: 0.0565\n",
            "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9304 - auc: 0.9963 - loss: 0.0565 - val_accuracy: 0.8879 - val_auc: 0.9867 - val_loss: 0.0820 - learning_rate: 2.5000e-04\n",
            "\n",
            "[RESULTS] Final Test Accuracy: 89.39%\n",
            "[RESULTS] Final Test AUC: 0.9891\n",
            "\\n[SAVE] Model saved to instrument_classifier_v2.keras\n",
            "[SAVE] Training analysis saved to training_analysis.png\n",
            "\n",
            "[EVALUATION] Generating confusion matrix and classification report...\n",
            "\n",
            "============================================================\n",
            "CLASSIFICATION REPORT (Per Instrument)\n",
            "============================================================\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          cello       0.97      0.87      0.92        45\n",
            "       clarinet       0.91      0.86      0.89        36\n",
            "          flute       0.85      0.82      0.84        34\n",
            "acoustic_guitar       0.88      0.85      0.86        52\n",
            "electric_guitar       0.88      0.58      0.70        36\n",
            "          organ       1.00      0.92      0.96        39\n",
            "          piano       0.90      0.96      0.93        79\n",
            "      saxophone       0.84      0.84      0.84        86\n",
            "        trumpet       0.95      0.85      0.90        96\n",
            "         violin       0.92      0.85      0.88        84\n",
            "          voice       0.99      0.96      0.97        73\n",
            "\n",
            "      micro avg       0.92      0.86      0.89       660\n",
            "      macro avg       0.92      0.85      0.88       660\n",
            "   weighted avg       0.92      0.86      0.89       660\n",
            "    samples avg       0.86      0.86      0.86       660\n",
            "\n",
            "[SAVE] Confusion matrices saved to confusion_matrices.png\n",
            "\n",
            "============================================================\n",
            "FINAL TRAINING RESULTS\n",
            "============================================================\n",
            "Training Accuracy:   92.99%\n",
            "Validation Accuracy: 88.79%\n",
            "Accuracy Gap:        4.20% ✓ Good\n",
            "Test Accuracy:       89.39%\n",
            "Test AUC:            0.9891\n",
            "============================================================\n",
            "\n",
            "Exported instrument recognition result to instrument_recognition_result.json\n",
            "[EXPORT] PDF report saved to instrument_recognition_report.pdf\n",
            "\n",
            "[COMPLETE] All tasks finished successfully!\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables BEFORE any imports\n",
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Suppress TensorFlow info/warning messages\n",
        "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"  # Disable oneDNN to prevent memory issues\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"  # Avoid protobuf issues\n",
        "\n",
        "print(\"[STARTUP] Environment variables configured\", flush=True)\n",
        "\n",
        "# Global configuration for the instrument recognition system\n",
        "CONFIG = {\n",
        "    \"sample_rate\": 22050,\n",
        "    \"mel_bands\": [64, 96, 128],\n",
        "    \"n_fft\": 2048,\n",
        "    \"hop_length\": 512,\n",
        "    \"learning_rate\": 0.001,  # Balanced learning rate\n",
        "    \"class_map\": {  # Default mapping, will be dynamically updated based on data\n",
        "        0: \"cello\",\n",
        "        1: \"clarinet\",\n",
        "        2: \"flute\",\n",
        "        3: \"acoustic_guitar\",\n",
        "        4: \"electric_guitar\",\n",
        "        5: \"organ\",\n",
        "        6: \"piano\",\n",
        "        7: \"saxophone\",\n",
        "        8: \"trumpet\",\n",
        "        9: \"violin\",\n",
        "        10: \"voice\",\n",
        "    },\n",
        "    \"test_size\": 0.2,\n",
        "    \"random_state\": 42,\n",
        "    \"max_files_per_instrument\": 350,\n",
        "    \"augmentation_ratio\": 0.70,  # Increased to 70% for maximum diversity\n",
        "}\n",
        "\n",
        "print(\"[STARTUP] Loading libraries (this may take 30-60 seconds)...\", flush=True)\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Input, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import signal\n",
        "\n",
        "# Configure TensorFlow memory growth to prevent OOM\n",
        "try:\n",
        "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"[MEMORY] Configured {len(gpus)} GPU(s) with memory growth\", flush=True)\n",
        "    else:\n",
        "        print(\"[MEMORY] Running on CPU - using optimized memory settings\", flush=True)\n",
        "except Exception as e:\n",
        "    print(f\"[MEMORY] Using default memory configuration: {e}\", flush=True)\n",
        "\n",
        "print(\"[STARTUP] All libraries loaded successfully!\", flush=True)\n",
        "\n",
        "\n",
        "# MultiResolutionCNN: Multi-input CNN for multi-resolution mel spectrograms\n",
        "class MultiResolutionCNN:\n",
        "    def __init__(self, input_shapes, num_classes):\n",
        "        # input_shapes: list of shapes, e.g. [(64, 259, 1), (96, 259, 1), (128, 259, 1)]\n",
        "        inputs = []\n",
        "        processed = []\n",
        "        for shape in input_shapes:\n",
        "            inp = Input(shape=shape)\n",
        "            # First conv block - ANTI-OVERFITTING measures applied\n",
        "            x = layers.Conv2D(\n",
        "                64,\n",
        "                (3, 3),\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(\n",
        "                    0.00015\n",
        "                ),  # Strong regularization\n",
        "            )(inp)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.MaxPooling2D((2, 2))(x)\n",
        "            x = layers.Dropout(0.35)(x)  # Strong dropout\n",
        "\n",
        "            # Second conv block\n",
        "            x = layers.Conv2D(\n",
        "                128,\n",
        "                (3, 3),\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(0.00015),\n",
        "            )(x)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.MaxPooling2D((2, 2))(x)\n",
        "            x = layers.Dropout(0.40)(x)  #  Strong dropout\n",
        "\n",
        "            # Third conv block\n",
        "            x = layers.Conv2D(\n",
        "                256,\n",
        "                (3, 3),\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(0.0002),\n",
        "            )(x)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.MaxPooling2D((2, 2))(x)\n",
        "            x = layers.Dropout(0.45)(x)  #  Strong dropout\n",
        "\n",
        "            # Fourth conv block for deeper features\n",
        "            x = layers.Conv2D(\n",
        "                256,\n",
        "                (3, 3),\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(0.0002),\n",
        "            )(x)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "\n",
        "            # Global pooling\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "            processed.append(x)\n",
        "            inputs.append(inp)\n",
        "        # Concatenate features from all resolutions\n",
        "        if len(processed) > 1:\n",
        "            x = layers.Concatenate()(processed)\n",
        "        else:\n",
        "            x = processed[0]\n",
        "        # Dense layers with VERY STRONG OVERFITTING measures\n",
        "        x = layers.Dense(\n",
        "            512,\n",
        "            activation=\"relu\",\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.0002),\n",
        "        )(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(0.50)(x)  # Very strong dropout\n",
        "        x = layers.Dense(\n",
        "            256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.0002)\n",
        "        )(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(0.45)(x)  # Strong dropout\n",
        "        x = layers.Dense(\n",
        "            128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.0002)\n",
        "        )(x)\n",
        "        x = layers.Dropout(0.40)(x)  #  Strong dropout\n",
        "        output = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "        self.model = Model(inputs=inputs, outputs=output)\n",
        "        self.model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(\n",
        "                learning_rate=CONFIG.get(\"learning_rate\", 0.001)\n",
        "            ),\n",
        "            loss=\"binary_crossentropy\",\n",
        "            metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")],\n",
        "        )\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=200):\n",
        "        callbacks = [\n",
        "            # Early stopping with VERY strict monitoring\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                patience=15,  # Stop if no\n",
        "                restore_best_weights=True,\n",
        "                monitor=\"val_loss\",\n",
        "                min_delta=0.0001,\n",
        "                verbose=1,\n",
        "            ),\n",
        "            tf.keras.callbacks.ModelCheckpoint(\n",
        "                \"best_model.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1\n",
        "            ),\n",
        "            # Reduce learning rate when validation loss plateaus\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                factor=0.5, patience=8, min_lr=1e-7, monitor=\"val_loss\", verbose=1\n",
        "            ),\n",
        "        ]\n",
        "        history = self.model.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=32,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1,\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        return self.model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "class AudioProcessor:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.sample_rate = config.get(\"sample_rate\", 22050)\n",
        "        self.mel_bands = config.get(\"mel_bands\", [64, 96, 128])\n",
        "        self.n_fft = config.get(\"n_fft\", 2048)\n",
        "        self.hop_length = config.get(\"hop_length\", 512)\n",
        "\n",
        "    def load_audio(self, file_path):\n",
        "        audio, _ = librosa.load(file_path, sr=self.sample_rate, mono=True)\n",
        "        return audio\n",
        "\n",
        "    def augment_audio(self, audio):\n",
        "        \"\"\"Apply BALANCED audio augmentation - ANTI-OVERFITTING\"\"\"\n",
        "        import random\n",
        "\n",
        "        augmented = audio.copy()\n",
        "\n",
        "        rand = random.random()\n",
        "\n",
        "        # Random time stretch\n",
        "        if rand < 0.40:\n",
        "            rate = random.uniform(0.90, 1.10)\n",
        "            augmented = librosa.effects.time_stretch(augmented, rate=rate)\n",
        "\n",
        "        # Random pitch shift\n",
        "        elif rand < 0.75:\n",
        "            n_steps = random.uniform(-2, 2)\n",
        "            augmented = librosa.effects.pitch_shift(\n",
        "                augmented, sr=self.sample_rate, n_steps=n_steps\n",
        "            )\n",
        "\n",
        "        # Add random noise (40% probability)\n",
        "        if random.random() < 0.4:\n",
        "            noise = np.random.randn(len(augmented)) * random.uniform(0.003, 0.007)\n",
        "            augmented = augmented + noise\n",
        "\n",
        "        # Random volume adjustment (40% probability)\n",
        "        if random.random() < 0.4:\n",
        "            volume_factor = random.uniform(0.88, 1.12)\n",
        "            augmented = augmented * volume_factor\n",
        "\n",
        "        # Random low-pass filter (20% probability)\n",
        "        if random.random() < 0.2:\n",
        "            cutoff_freq = random.uniform(3500, 8000)\n",
        "            sos = signal.butter(\n",
        "                5, cutoff_freq, btype=\"low\", fs=self.sample_rate, output=\"sos\"\n",
        "            )\n",
        "            augmented = signal.sosfilt(sos, augmented)\n",
        "\n",
        "        # Random time shift (25% probability)\n",
        "        if random.random() < 0.25:\n",
        "            shift = random.randint(\n",
        "                -int(0.10 * self.sample_rate), int(0.10 * self.sample_rate)\n",
        "            )\n",
        "            augmented = np.roll(augmented, shift)\n",
        "\n",
        "        return augmented\n",
        "\n",
        "    def extract_multi_resolution_features(self, audio, target_time_dim=259):\n",
        "        features = {}\n",
        "        for n_mels in self.mel_bands:\n",
        "            mel = librosa.feature.melspectrogram(\n",
        "                y=audio,\n",
        "                sr=self.sample_rate,\n",
        "                n_fft=self.n_fft,\n",
        "                hop_length=self.hop_length,\n",
        "                n_mels=n_mels,\n",
        "                power=2.0,\n",
        "            )\n",
        "            mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "            # Normalize each mel spectrogram (mean=0, std=1)\n",
        "            mel_db = (mel_db - np.mean(mel_db)) / (np.std(mel_db) + 1e-8)\n",
        "            # Ensure float32 to reduce memory\n",
        "            mel_db = mel_db.astype(np.float32)\n",
        "            # Pad or crop to target_time_dim\n",
        "            if mel_db.shape[1] < target_time_dim:\n",
        "                pad_width = target_time_dim - mel_db.shape[1]\n",
        "                mel_db = np.pad(mel_db, ((0, 0), (0, pad_width)), mode=\"constant\")\n",
        "            elif mel_db.shape[1] > target_time_dim:\n",
        "                mel_db = mel_db[:, :target_time_dim]\n",
        "            features[f\"mel_{n_mels}\"] = np.expand_dims(mel_db, axis=-1)\n",
        "        return features\n",
        "\n",
        "    def mixup_data(self, X, y, alpha=0.4):\n",
        "        \"\"\"Apply mixup augmentation during training for better generalization\"\"\"\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        batch_size = len(X[0]) if isinstance(X, list) else len(X)\n",
        "        index = np.random.permutation(batch_size)\n",
        "\n",
        "        if isinstance(X, list):\n",
        "            mixed_X = [lam * x + (1 - lam) * x[index] for x in X]\n",
        "        else:\n",
        "            mixed_X = lam * X + (1 - lam) * X[index]\n",
        "\n",
        "        mixed_y = lam * y + (1 - lam) * y[index]\n",
        "        return mixed_X, mixed_y\n",
        "\n",
        "\n",
        "# Feature caching for faster training\n",
        "import hashlib\n",
        "import pickle\n",
        "\n",
        "\n",
        "def get_cache_path(file_path, augment=False):\n",
        "    \"\"\"Generate cache file path for audio features\"\"\"\n",
        "    file_hash = hashlib.md5(file_path.encode()).hexdigest()\n",
        "    suffix = \"_aug\" if augment else \"\"\n",
        "    version = \"_v10\"  # Updated version - NO OVERFITTING\n",
        "    return f\"CNN/cache/{file_hash}{suffix}{version}.pkl\"\n",
        "\n",
        "\n",
        "def load_cached_features(file_path, augment=False):\n",
        "    \"\"\"Load features from cache if available\"\"\"\n",
        "    cache_path = get_cache_path(file_path, augment)\n",
        "    if os.path.exists(cache_path):\n",
        "        with open(cache_path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_cached_features(file_path, features, augment=False):\n",
        "    \"\"\"Save features to cache\"\"\"\n",
        "    cache_dir = \"CNN/cache\"\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    cache_path = get_cache_path(file_path, augment)\n",
        "    with open(cache_path, \"wb\") as f:\n",
        "        pickle.dump(features, f)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\" * 70, flush=True)\n",
        "    print(\"    CNN-BASED MUSIC INSTRUMENT RECOGNITION SYSTEM\", flush=True)\n",
        "    print(\"    [NO OVERFITTING - BALANCED & OPTIMIZED v10]\", flush=True)\n",
        "    print(\"=\" * 70 + \"\\n\", flush=True)\n",
        "\n",
        "    # Initialize components\n",
        "    print(\"[INIT] Initializing audio processor...\", flush=True)\n",
        "    processor = AudioProcessor(CONFIG)\n",
        "    print(\n",
        "        f\"[INIT] ANTI-OVERFITTING measures: 70% augmentation, very strong regularization - TARGET GAP < 5%\",\n",
        "        flush=True,\n",
        "    )\n",
        "    print(\"[INIT] Audio processor ready\\n\", flush=True)\n",
        "\n",
        "    # Load dataset from IRMAS-TrainingData\n",
        "    import glob\n",
        "\n",
        "    print(\"[DATA] Loading training data from IRMAS dataset...\", flush=True)\n",
        "    data_dir = r\"/content/drive/MyDrive/IRMAS-TrainingData\"\n",
        "    print(f\"[DATA] Dataset location: {data_dir}\", flush=True)\n",
        "    instrument_folders = [\n",
        "        f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))\n",
        "    ]\n",
        "\n",
        "    # Dynamically map IRMAS short names\n",
        "    irmas_to_full = {\n",
        "        \"cel\": \"cello\",\n",
        "        \"cla\": \"clarinet\",\n",
        "        \"flu\": \"flute\",\n",
        "        \"gac\": \"acoustic_guitar\",\n",
        "        \"gel\": \"electric_guitar\",\n",
        "        \"org\": \"organ\",\n",
        "        \"pia\": \"piano\",\n",
        "        \"sax\": \"saxophone\",\n",
        "        \"tru\": \"trumpet\",\n",
        "        \"vio\": \"violin\",\n",
        "        \"voi\": \"voice\",\n",
        "    }\n",
        "\n",
        "    # Collect unique instruments dynamically\n",
        "    discovered_instruments = set()\n",
        "    audio_files = []\n",
        "    labels = []\n",
        "\n",
        "    # For mel spectrogram visualization\n",
        "    sample_files_per_instrument = {}\n",
        "\n",
        "    for inst in instrument_folders:\n",
        "        if inst in irmas_to_full:\n",
        "            print(f\"[DATA] Scanning folder: {inst}\", flush=True)\n",
        "            wav_files = glob.glob(os.path.join(data_dir, inst, \"*.wav\"))\n",
        "            mapped_label = irmas_to_full[inst]\n",
        "            discovered_instruments.add(mapped_label)\n",
        "            audio_files.extend(wav_files)\n",
        "            labels.extend([mapped_label] * len(wav_files))\n",
        "\n",
        "            # Store first file for mel spectrogram visualization\n",
        "            if mapped_label not in sample_files_per_instrument and len(wav_files) > 0:\n",
        "                sample_files_per_instrument[mapped_label] = wav_files[0]\n",
        "\n",
        "            print(\n",
        "                f\"[DATA]   Found {len(wav_files)} files for {mapped_label}\",\n",
        "                flush=True,\n",
        "            )\n",
        "\n",
        "    # Update CONFIG with discovered instruments\n",
        "    print(\n",
        "        f\"\\n[DATA] Discovered {len(discovered_instruments)} unique instruments: {sorted(discovered_instruments)}\",\n",
        "        flush=True,\n",
        "    )\n",
        "\n",
        "    # Limit files per instrument\n",
        "    max_files_per_instrument = CONFIG[\"max_files_per_instrument\"]\n",
        "    print(\n",
        "        f\"\\n[DATA] Using {max_files_per_instrument} files per instrument...\",\n",
        "        flush=True,\n",
        "    )\n",
        "    filtered_files = []\n",
        "    filtered_labels = []\n",
        "    instrument_counts = {}\n",
        "\n",
        "    for file, label in zip(audio_files, labels):\n",
        "        if label not in instrument_counts:\n",
        "            instrument_counts[label] = 0\n",
        "        if instrument_counts[label] < max_files_per_instrument:\n",
        "            filtered_files.append(file)\n",
        "            filtered_labels.append(label)\n",
        "            instrument_counts[label] += 1\n",
        "\n",
        "    audio_files = filtered_files\n",
        "    labels = filtered_labels\n",
        "\n",
        "    print(f\"[DATA] Total files to process: {len(audio_files)}\", flush=True)\n",
        "    for label, count in instrument_counts.items():\n",
        "        print(f\"[DATA]   {label}: {count} files\", flush=True)\n",
        "\n",
        "    # Generate mel spectrogram visualizations\n",
        "    print(\n",
        "        f\"\\n[VISUALIZATION] Generating mel spectrograms for all instruments...\",\n",
        "        flush=True,\n",
        "    )\n",
        "    fig, axes = plt.subplots(4, 3, figsize=(15, 16))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i, (instrument, file_path) in enumerate(\n",
        "        sorted(sample_files_per_instrument.items())\n",
        "    ):\n",
        "        try:\n",
        "            audio = processor.load_audio(file_path)\n",
        "            mel = librosa.feature.melspectrogram(\n",
        "                y=audio,\n",
        "                sr=CONFIG[\"sample_rate\"],\n",
        "                n_fft=CONFIG[\"n_fft\"],\n",
        "                hop_length=CONFIG[\"hop_length\"],\n",
        "                n_mels=128,\n",
        "            )\n",
        "            mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "            img = librosa.display.specshow(\n",
        "                mel_db,\n",
        "                sr=CONFIG[\"sample_rate\"],\n",
        "                hop_length=CONFIG[\"hop_length\"],\n",
        "                x_axis=\"time\",\n",
        "                y_axis=\"mel\",\n",
        "                ax=axes[i],\n",
        "                cmap=\"viridis\",\n",
        "            )\n",
        "            axes[i].set_title(f\"{instrument}\", fontsize=12, fontweight=\"bold\")\n",
        "            axes[i].set_xlabel(\"Time (s)\", fontsize=10)\n",
        "            axes[i].set_ylabel(\"Frequency (Hz)\", fontsize=10)\n",
        "            fig.colorbar(img, ax=axes[i], format=\"%+2.0f dB\")\n",
        "        except Exception as e:\n",
        "            print(\n",
        "                f\"[WARNING] Could not generate mel spectrogram for {instrument}: {e}\",\n",
        "                flush=True,\n",
        "            )\n",
        "\n",
        "    # Hide extra subplot\n",
        "    axes[-1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"mel_spectrograms.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "    print(f\"[SAVE] Mel spectrograms saved to mel_spectrograms.png\", flush=True)\n",
        "\n",
        "    print(\n",
        "        \"\\n[FEATURES] Extracting features with 70% augmentation (ANTI-OVERFITTING - GAP < 5%)...\",\n",
        "        flush=True,\n",
        "    )\n",
        "\n",
        "    # Multi-label binarizer for instrument labels\n",
        "    from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "    X, y = [], []\n",
        "    processed_files = []\n",
        "    count = 0\n",
        "\n",
        "    # Process files with balanced augmentation\n",
        "    for file, label in zip(audio_files, labels):\n",
        "        if count % 50 == 0:\n",
        "            print(\n",
        "                f\"[FEATURES] Processed {count}/{len(audio_files)} files...\", flush=True\n",
        "            )\n",
        "        try:\n",
        "            # Try to load from cache first\n",
        "            cached_features = load_cached_features(file, augment=False)\n",
        "            if cached_features is not None:\n",
        "                features = cached_features\n",
        "            else:\n",
        "                audio = processor.load_audio(file)\n",
        "                features = processor.extract_multi_resolution_features(audio)\n",
        "                save_cached_features(file, features, augment=False)\n",
        "\n",
        "            X.append([features[f\"mel_{n}\"] for n in CONFIG[\"mel_bands\"]])\n",
        "            y.append([label] if isinstance(label, str) else list(label))\n",
        "            processed_files.append(file)\n",
        "            count += 1\n",
        "\n",
        "            # Augmentation with 70% ratio\n",
        "\n",
        "            if count <= len(audio_files) * CONFIG[\"augmentation_ratio\"]:\n",
        "                cached_aug = load_cached_features(file, augment=True)\n",
        "                if cached_aug is not None:\n",
        "                    aug_features = cached_aug\n",
        "                else:\n",
        "                    audio = processor.load_audio(file)\n",
        "                    aug_audio = processor.augment_audio(audio)\n",
        "                    aug_features = processor.extract_multi_resolution_features(\n",
        "                        aug_audio\n",
        "                    )\n",
        "                    save_cached_features(file, aug_features, augment=True)\n",
        "\n",
        "                X.append([aug_features[f\"mel_{n}\"] for n in CONFIG[\"mel_bands\"]])\n",
        "                y.append([label] if isinstance(label, str) else list(label))\n",
        "                processed_files.append(file + \"_aug\")\n",
        "\n",
        "            if count % 50 == 0:\n",
        "                print(\n",
        "                    f\"Processed {count}/{len(audio_files)} files (with augmentation: {len(X)} samples)...\"\n",
        "                )\n",
        "                import gc\n",
        "\n",
        "                gc.collect()\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping file {file} due to error: {e}\")\n",
        "\n",
        "    # Only use the successfully processed samples\n",
        "    min_len = min(len(X), len(y), len(processed_files))\n",
        "    X = X[:min_len]\n",
        "    y = y[:min_len]\n",
        "    processed_files = processed_files[:min_len]\n",
        "\n",
        "    # Clear memory\n",
        "    import gc\n",
        "\n",
        "    gc.collect()\n",
        "    print(f\"\\n[MEMORY] Garbage collection completed\", flush=True)\n",
        "\n",
        "    # Get unique instruments\n",
        "    unique_instruments = sorted(\n",
        "        set([label[0] if isinstance(label, list) else label for label in y])\n",
        "    )\n",
        "    print(\n",
        "        f\"[DATA] Training with {len(unique_instruments)} instrument classes: {unique_instruments}\",\n",
        "        flush=True,\n",
        "    )\n",
        "\n",
        "    # Binarize labels\n",
        "    mlb = MultiLabelBinarizer(classes=unique_instruments)\n",
        "    y = mlb.fit_transform(y)\n",
        "\n",
        "    print(f\"[DATA] Label shape after binarization: {y.shape}\", flush=True)\n",
        "\n",
        "    if len(X) < 2 or len(y) < 2:\n",
        "        print(\"Not enough valid samples to train/test. Please add more data.\")\n",
        "    else:\n",
        "        print(f\"Length of X: {len(X)}\")\n",
        "        print(f\"Length of y: {len(y)}\")\n",
        "        print(f\"Length of processed_files: {len(processed_files)}\")\n",
        "\n",
        "        # Stack samples\n",
        "        X_np = [\n",
        "            np.stack([sample[i] for sample in X], axis=0)\n",
        "            for i in range(len(CONFIG[\"mel_bands\"]))\n",
        "        ]\n",
        "\n",
        "        # Print shapes\n",
        "        print(f\"\\n[FEATURES] Feature shapes:\")\n",
        "        for i, shape in enumerate([x.shape for x in X_np]):\n",
        "            print(f\"[FEATURES]   Resolution {i+1}: {shape}\")\n",
        "\n",
        "        # Train-test split\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        idx = np.arange(len(y))\n",
        "        train_idx, test_idx, y_train, y_test = train_test_split(\n",
        "            idx, y, test_size=CONFIG[\"test_size\"], random_state=CONFIG[\"random_state\"]\n",
        "        )\n",
        "        X_train = [x[train_idx] for x in X_np]\n",
        "        X_test = [x[test_idx] for x in X_np]\n",
        "\n",
        "        print(f\"\\nTraining samples: {len(train_idx)}, Test samples: {len(test_idx)}\")\n",
        "        print(f\"Training data shapes: {[x.shape for x in X_train]}\")\n",
        "\n",
        "        # Initialize model\n",
        "        num_classes = y.shape[1]\n",
        "        input_shapes = [(x.shape[1], x.shape[2], 1) for x in X_np]\n",
        "        print(\n",
        "            f\"\\n[MODEL] Creating NO-OVERFITTING CNN for {num_classes} classes...\",\n",
        "            flush=True,\n",
        "        )\n",
        "        print(f\"[MODEL] Input shapes: {input_shapes}\", flush=True)\n",
        "        print(\n",
        "            f\"[MODEL] ANTI-OVERFITTING: Dropout 0.35-0.50, L2 reg 0.00015-0.0002, Early stop patience=15 - TARGET GAP < 5%\",\n",
        "            flush=True,\n",
        "        )\n",
        "        model = MultiResolutionCNN(\n",
        "            input_shapes=input_shapes,\n",
        "            num_classes=num_classes,\n",
        "        )\n",
        "\n",
        "        print(f\"\\n[MODEL] Model Summary:\")\n",
        "        model.model.summary()\n",
        "\n",
        "        # Train model\n",
        "        print(\n",
        "            f\"\\n[TRAINING] Starting NO-OVERFITTING training...\",\n",
        "            flush=True,\n",
        "        )\n",
        "        print(\n",
        "            f\"[TRAINING] Learning rate: {CONFIG['learning_rate']}\",\n",
        "            flush=True,\n",
        "        )\n",
        "        print(f\"[TRAINING] Batch size: 32\", flush=True)\n",
        "        print(f\"[TRAINING] Augmentation: 70% (ANTI-OVERFITTING - GAP < 5%)\", flush=True)\n",
        "        print(\n",
        "            f\"[TRAINING] Regularization: L2=0.00015-0.0002 (ANTI-OVERFITTING - GAP < 5%)\",\n",
        "            flush=True,\n",
        "        )\n",
        "        print(\n",
        "            f\"[TRAINING] Dropout: 0.35-0.50 (ANTI-OVERFITTING - GAP < 5%)\", flush=True\n",
        "        )\n",
        "        print(\n",
        "            f\"[TRAINING] Early stopping: 15 epochs patience (ANTI-OVERFITTING - GAP < 5%)\\n\",\n",
        "            flush=True,\n",
        "        )\n",
        "        history = model.train(X_train, y_train, X_test, y_test)\n",
        "\n",
        "        # Evaluate\n",
        "        test_loss, test_acc, test_auc = model.evaluate(X_test, y_test)\n",
        "        print(f\"\\n[RESULTS] Final Test Loss: {test_loss:.4f}\")\n",
        "        print(f\"[RESULTS] Final Test Accuracy: {test_acc:.2%}\")\n",
        "        print(f\"[RESULTS] Final Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "        # Save model\n",
        "        model.model.save(\"instrument_classifier_v10_no_overfitting.keras\")\n",
        "        print(\n",
        "            f\"\\n[SAVE] Model saved to instrument_classifier_v10_no_overfitting.keras\",\n",
        "            flush=True,\n",
        "        )\n",
        "\n",
        "        # Enhanced Visualization\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Plot 1: Accuracy\n",
        "        axes[0].plot(\n",
        "            history.history[\"accuracy\"], label=\"Training Accuracy\", linewidth=2\n",
        "        )\n",
        "        axes[0].plot(\n",
        "            history.history[\"val_accuracy\"], label=\"Validation Accuracy\", linewidth=2\n",
        "        )\n",
        "        axes[0].set_title(\"Model Accuracy Over Epochs\", fontsize=14, fontweight=\"bold\")\n",
        "        axes[0].set_xlabel(\"Epoch\", fontsize=12)\n",
        "        axes[0].set_ylabel(\"Accuracy\", fontsize=12)\n",
        "        axes[0].legend(fontsize=10)\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Calculate and display final gap\n",
        "        final_train_acc = history.history[\"accuracy\"][-1]\n",
        "        final_val_acc = history.history[\"val_accuracy\"][-1]\n",
        "        gap = abs(final_train_acc - final_val_acc)\n",
        "        gap_status = (\n",
        "            \"🎯 PERFECT! NO OVERFITTING!\"\n",
        "            if gap < 0.03\n",
        "            else (\n",
        "                \"✓ EXCELLENT! GAP < 5% TARGET ACHIEVED!\"\n",
        "                if gap < 0.05\n",
        "                else (\n",
        "                    \"⚠ WARNING: Gap ≥ 5% - Overfitting detected!\"\n",
        "                    if gap < 0.08\n",
        "                    else \"❌ SEVERE OVERFITTING!\"\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        axes[0].text(\n",
        "            0.02,\n",
        "            0.98,\n",
        "            f\"Final Gap: {gap:.2%}\\n{gap_status}\\nTarget: < 5%\",\n",
        "            transform=axes[0].transAxes,\n",
        "            fontsize=10,\n",
        "            verticalalignment=\"top\",\n",
        "            bbox=dict(\n",
        "                boxstyle=\"round\",\n",
        "                facecolor=(\n",
        "                    \"lightgreen\" if gap < 0.05 else \"yellow\" if gap < 0.08 else \"orange\"\n",
        "                ),\n",
        "                alpha=0.7,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # Plot 2: Loss\n",
        "        axes[1].plot(history.history[\"loss\"], label=\"Training Loss\", linewidth=2)\n",
        "        axes[1].plot(history.history[\"val_loss\"], label=\"Validation Loss\", linewidth=2)\n",
        "        axes[1].set_title(\"Model Loss Over Epochs\", fontsize=14, fontweight=\"bold\")\n",
        "        axes[1].set_xlabel(\"Epoch\", fontsize=12)\n",
        "        axes[1].set_ylabel(\"Loss\", fontsize=12)\n",
        "        axes[1].legend(fontsize=10)\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Display final loss values and gap\n",
        "        final_train_loss = history.history[\"loss\"][-1]\n",
        "        final_val_loss = history.history[\"val_loss\"][-1]\n",
        "        loss_gap = abs(final_train_loss - final_val_loss)\n",
        "        loss_gap_status = (\n",
        "            \"✓ NO OVERFITTING!\"\n",
        "            if loss_gap < 0.05\n",
        "            else \"✓ Good\" if loss_gap < 0.10 else \"⚠ Check\"\n",
        "        )\n",
        "        axes[1].text(\n",
        "            0.02,\n",
        "            0.98,\n",
        "            f\"Train: {final_train_loss:.4f}\\nVal: {final_val_loss:.4f}\\nGap: {loss_gap:.4f}\\n{loss_gap_status}\",\n",
        "            transform=axes[1].transAxes,\n",
        "            fontsize=10,\n",
        "            verticalalignment=\"top\",\n",
        "            bbox=dict(\n",
        "                boxstyle=\"round\",\n",
        "                facecolor=(\"lightgreen\" if loss_gap < 0.10 else \"yellow\"),\n",
        "                alpha=0.7,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"training_analysis.png\", dpi=150, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        print(f\"[SAVE] Training analysis saved to training_analysis.png\", flush=True)\n",
        "\n",
        "        # Generate confusion matrix and classification report\n",
        "        print(\n",
        "            f\"\\n[EVALUATION] Generating confusion matrix and classification report...\",\n",
        "            flush=True,\n",
        "        )\n",
        "        y_pred = model.model.predict(X_test, verbose=0)\n",
        "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "        y_test_classes = y_test.astype(int)\n",
        "\n",
        "        # Get class names\n",
        "        class_names = list(mlb.classes_)\n",
        "\n",
        "        # Multi-label classification report\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"CLASSIFICATION REPORT (Per Instrument)\")\n",
        "        print(f\"{'='*60}\")\n",
        "        report = classification_report(\n",
        "            y_test_classes, y_pred_classes, target_names=class_names, zero_division=0\n",
        "        )\n",
        "        print(report)\n",
        "\n",
        "        # Confusion matrix for each instrument\n",
        "        fig, axes = plt.subplots(4, 3, figsize=(15, 16))\n",
        "        axes = axes.ravel()\n",
        "        for i, instrument in enumerate(class_names):\n",
        "            cm = confusion_matrix(y_test_classes[:, i], y_pred_classes[:, i])\n",
        "            sns.heatmap(\n",
        "                cm,\n",
        "                annot=True,\n",
        "                fmt=\"d\",\n",
        "                cmap=\"Blues\",\n",
        "                ax=axes[i],\n",
        "                xticklabels=[\"Negative\", \"Positive\"],\n",
        "                yticklabels=[\"Negative\", \"Positive\"],\n",
        "            )\n",
        "            axes[i].set_title(f\"{instrument}\", fontsize=12, fontweight=\"bold\")\n",
        "            axes[i].set_ylabel(\"True Label\", fontsize=10)\n",
        "            axes[i].set_xlabel(\"Predicted Label\", fontsize=10)\n",
        "\n",
        "        # Hide extra subplot\n",
        "        axes[-1].axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"confusion_matrices.png\", dpi=150, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        print(f\"[SAVE] Confusion matrices saved to confusion_matrices.png\", flush=True)\n",
        "\n",
        "        # Print detailed results\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"FINAL RESULTS - NO OVERFITTING v10\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Training Accuracy:   {final_train_acc:.2%}\")\n",
        "        print(f\"Validation Accuracy: {final_val_acc:.2%}\")\n",
        "        print(f\"Accuracy Gap:        {gap:.2%} (Target: < 5% MANDATORY)\")\n",
        "\n",
        "        overfitting_status = (\n",
        "            \"🎯 PERFECT! NO OVERFITTING! Gap < 3%\"\n",
        "            if gap < 0.03\n",
        "            else (\n",
        "                \"✅ EXCELLENT! GAP < 5% TARGET ACHIEVED!\"\n",
        "                if gap < 0.05\n",
        "                else (\n",
        "                    \"⚠️ WARNING: Gap ≥ 5% - OVERFITTING DETECTED!\"\n",
        "                    if gap < 0.08\n",
        "                    else \"❌ SEVERE OVERFITTING! Gap > 8% - Need stronger regularization\"\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        print(f\"Overfitting Status:  {overfitting_status}\")\n",
        "        print(f\"\\nTraining Loss:       {final_train_loss:.4f}\")\n",
        "        print(f\"Validation Loss:     {final_val_loss:.4f}\")\n",
        "        print(f\"Loss Gap:            {loss_gap:.4f}\")\n",
        "        print(f\"Test Accuracy:       {test_acc:.2%}\")\n",
        "        print(f\"Test Loss:           {test_loss:.4f}\")\n",
        "        print(f\"Test AUC:            {test_auc:.4f}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        # Sliding window inference for instrument intensity over time\n",
        "        def sliding_window_predict(audio_file, window_size=1.0, hop_size=0.5):\n",
        "            audio, sr = librosa.load(audio_file, sr=CONFIG[\"sample_rate\"])\n",
        "            duration = librosa.get_duration(y=audio, sr=sr)\n",
        "            times = np.arange(0, duration - window_size, hop_size)\n",
        "            all_preds = []\n",
        "            for t in times:\n",
        "                start = int(t * sr)\n",
        "                end = int((t + window_size) * sr)\n",
        "                segment = audio[start:end]\n",
        "                if len(segment) < int(window_size * sr):\n",
        "                    pad = np.zeros(int(window_size * sr) - len(segment))\n",
        "                    segment = np.concatenate([segment, pad])\n",
        "                features = processor.extract_multi_resolution_features(segment)\n",
        "                X_window = [\n",
        "                    np.expand_dims(features[f\"mel_{n}\"], axis=0)\n",
        "                    for n in CONFIG[\"mel_bands\"]\n",
        "                ]\n",
        "                pred = model.model.predict(X_window, verbose=0)\n",
        "                all_preds.append(pred[0])\n",
        "            return np.array(all_preds), times\n",
        "\n",
        "        # Example: run sliding window on first successfully processed file\n",
        "        if len(processed_files) > 0:\n",
        "            preds, times = sliding_window_predict(processed_files[0])\n",
        "            # Visualization\n",
        "            import matplotlib.pyplot as plt\n",
        "\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            for i, inst in enumerate(mlb.classes_):\n",
        "                plt.plot(times, preds[:, i], label=inst)\n",
        "            plt.xlabel(\"Time (s)\")\n",
        "            plt.ylabel(\"Predicted Probability\")\n",
        "            plt.title(\"Instrument Intensity Over Time\")\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(\"instrument_intensity_timeline.png\")\n",
        "            plt.close()\n",
        "\n",
        "            # JSON export\n",
        "            import json\n",
        "\n",
        "            result = {\n",
        "                \"audio_file\": processed_files[0],\n",
        "                \"detected_instruments\": {\n",
        "                    inst: float(np.max(preds[:, i]))\n",
        "                    for i, inst in enumerate(mlb.classes_)\n",
        "                },\n",
        "                \"timeline\": [\n",
        "                    {\n",
        "                        \"time\": float(t),\n",
        "                        **{\n",
        "                            inst: float(preds[j, i])\n",
        "                            for i, inst in enumerate(mlb.classes_)\n",
        "                        },\n",
        "                    }\n",
        "                    for j, t in enumerate(times)\n",
        "                ],\n",
        "            }\n",
        "            with open(\"instrument_recognition_result.json\", \"w\") as f:\n",
        "                json.dump(result, f, indent=2)\n",
        "            print(\n",
        "                \"Exported instrument recognition result to instrument_recognition_result.json\"\n",
        "            )\n",
        "            # PDF export using matplotlib\n",
        "            from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "            pdf_filename = \"instrument_recognition_report.pdf\"\n",
        "            with PdfPages(pdf_filename) as pdf:\n",
        "                # Page 1: Title and Summary\n",
        "                fig = plt.figure(figsize=(8.5, 11))\n",
        "                fig.text(\n",
        "                    0.5,\n",
        "                    0.95,\n",
        "                    \"InstruPlay AI - Instrument Recognition Report\",\n",
        "                    ha=\"center\",\n",
        "                    fontsize=16,\n",
        "                    fontweight=\"bold\",\n",
        "                )\n",
        "                fig.text(\n",
        "                    0.5,\n",
        "                    0.90,\n",
        "                    f\"Audio File: {processed_files[0]}\",\n",
        "                    ha=\"center\",\n",
        "                    fontsize=10,\n",
        "                )\n",
        "                fig.text(\n",
        "                    0.5,\n",
        "                    0.87,\n",
        "                    f\"Analysis Date: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "                    ha=\"center\",\n",
        "                    fontsize=9,\n",
        "                    style=\"italic\",\n",
        "                )\n",
        "\n",
        "                # Detected Instruments Summary\n",
        "                fig.text(\n",
        "                    0.1, 0.80, \"Detected Instruments:\", fontsize=12, fontweight=\"bold\"\n",
        "                )\n",
        "                y_pos = 0.75\n",
        "                for inst in mlb.classes_:\n",
        "                    max_conf = float(np.max(preds[:, list(mlb.classes_).index(inst)]))\n",
        "                    status = \"Present\" if max_conf > 0.5 else \"Not Present\"\n",
        "                    color = \"green\" if max_conf > 0.5 else \"red\"\n",
        "                    fig.text(\n",
        "                        0.15,\n",
        "                        y_pos,\n",
        "                        f\"• {inst.replace('_', ' ').title()}: {status} (Confidence: {max_conf:.2%})\",\n",
        "                        fontsize=10,\n",
        "                        color=color,\n",
        "                    )\n",
        "                    y_pos -= 0.04\n",
        "\n",
        "                # Statistics\n",
        "                fig.text(\n",
        "                    0.1,\n",
        "                    y_pos - 0.05,\n",
        "                    \"Analysis Statistics:\",\n",
        "                    fontsize=12,\n",
        "                    fontweight=\"bold\",\n",
        "                )\n",
        "                y_pos -= 0.10\n",
        "                fig.text(\n",
        "                    0.15,\n",
        "                    y_pos,\n",
        "                    f\"• Total Instruments Detected: {sum(1 for i in mlb.classes_ if np.max(preds[:, list(mlb.classes_).index(i)]) > 0.5)}\",\n",
        "                    fontsize=10,\n",
        "                )\n",
        "                y_pos -= 0.04\n",
        "                fig.text(\n",
        "                    0.15,\n",
        "                    y_pos,\n",
        "                    f\"• Audio Duration: {times[-1]:.2f} seconds\",\n",
        "                    fontsize=10,\n",
        "                )\n",
        "                y_pos -= 0.04\n",
        "                fig.text(\n",
        "                    0.15, y_pos, f\"• Time Windows Analyzed: {len(times)}\", fontsize=10\n",
        "                )\n",
        "\n",
        "                plt.axis(\"off\")\n",
        "                pdf.savefig(fig, bbox_inches=\"tight\")\n",
        "                plt.close()\n",
        "\n",
        "                # Page 2: Instrument Intensity Timeline\n",
        "                fig = plt.figure(figsize=(11, 8.5))\n",
        "                for i, inst in enumerate(mlb.classes_):\n",
        "                    plt.plot(\n",
        "                        times,\n",
        "                        preds[:, i],\n",
        "                        label=inst.replace(\"_\", \" \").title(),\n",
        "                        linewidth=2,\n",
        "                    )\n",
        "                plt.xlabel(\"Time (seconds)\", fontsize=12)\n",
        "                plt.ylabel(\"Predicted Probability\", fontsize=12)\n",
        "                plt.title(\n",
        "                    \"Instrument Intensity Over Time\", fontsize=14, fontweight=\"bold\"\n",
        "                )\n",
        "                plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=9)\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                plt.tight_layout()\n",
        "                pdf.savefig(fig, bbox_inches=\"tight\")\n",
        "                plt.close()\n",
        "\n",
        "                # Page 3: Confidence Bar Chart\n",
        "                fig = plt.figure(figsize=(8.5, 11))\n",
        "                instruments = [inst.replace(\"_\", \" \").title() for inst in mlb.classes_]\n",
        "                max_confidences = [\n",
        "                    float(np.max(preds[:, i])) for i in range(len(mlb.classes_))\n",
        "                ]\n",
        "                colors = [\n",
        "                    \"green\" if conf > 0.5 else \"orange\" if conf > 0.3 else \"red\"\n",
        "                    for conf in max_confidences\n",
        "                ]\n",
        "\n",
        "                plt.barh(instruments, max_confidences, color=colors, alpha=0.7)\n",
        "                plt.xlabel(\"Maximum Confidence\", fontsize=12)\n",
        "                plt.title(\n",
        "                    \"Instrument Detection Confidence\", fontsize=14, fontweight=\"bold\"\n",
        "                )\n",
        "                plt.xlim(0, 1)\n",
        "                plt.axvline(\n",
        "                    x=0.5,\n",
        "                    color=\"black\",\n",
        "                    linestyle=\"--\",\n",
        "                    linewidth=1,\n",
        "                    alpha=0.5,\n",
        "                    label=\"Threshold (0.5)\",\n",
        "                )\n",
        "                plt.legend()\n",
        "                plt.grid(True, alpha=0.3, axis=\"x\")\n",
        "                plt.tight_layout()\n",
        "                pdf.savefig(fig, bbox_inches=\"tight\")\n",
        "                plt.close()\n",
        "print(\"\\n✅ VERY STRONG ANTI-OVERFITTING MEASURES SUCCESSFULLY APPLIED:\")\n",
        "print(f\"[EXPORT] PDF report saved to {pdf_filename}\")\n",
        "\n",
        "print(\"\\n[COMPLETE] OVERFITTING < 5% training finished!\")\n",
        "print(\"\\n✅ VERY STRONG ANTI-OVERFITTING MEASURES SUCCESSFULLY APPLIED:\")\n",
        "print(\"   1. Dropout layers: 0.35-0.50 (prevents memorization)\")\n",
        "print(\"   2. L2 Regularization: 0.00015-0.0002 (strong weight penalty)\")\n",
        "plt.close()\n",
        "\n",
        "print(f\"[EXPORT] PDF report saved to {pdf_filename}\")\n",
        "\n",
        "print(\"\\n[COMPLETE] OVERFITTING < 5% training finished!\")\n",
        "print(\"\\n✅ VERY STRONG ANTI-OVERFITTING MEASURES SUCCESSFULLY APPLIED:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXYkqtiN7w13",
        "outputId": "565d1985-a2a2-4cd2-e7c3-1bd0c7c9ce0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit               #  Step 1: Install Required Packages\n",
        "!pip install librosa\n",
        "!pip install tensorflow\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "HujNSGff7ykf",
        "outputId": "2e835523-0566-4609-bf11-895e11c1f2da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload streamlit_app.py:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3aed019c-94d5-46d3-a3d2-be20d85a4a88\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3aed019c-94d5-46d3-a3d2-be20d85a4a88\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving streamlit_app.py to streamlit_app.py\n",
            "\n",
            "Upload instrument_classifier_v2.keras:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8d8770a0-3ae6-44dd-b27d-d711367e7934\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8d8770a0-3ae6-44dd-b27d-d711367e7934\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving instrument_classifier_v2.keras to instrument_classifier_v2.keras\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Step 2: Upload Your Files Upload the following files from your local machine:\n",
        "# streamlit_app.py\n",
        "# instrument_classifier_v2.keras (or best_model.keras)\n",
        "# music_icon.svg (optional)\n",
        "\n",
        "print(\"Upload streamlit_app.py:\")\n",
        "uploaded_streamlit = files.upload()\n",
        "\n",
        "print(\"\\nUpload instrument_classifier_v2.keras:\")\n",
        "uploaded_model = files.upload()\n",
        "\n",
        "# print(\"\\nUpload music_icon.svg (optional):\")\n",
        "# uploaded_icon = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n7xh9NQ73Pj"
      },
      "outputs": [],
      "source": [
        "from pyngrok import (\n",
        "    ngrok,\n",
        ")  # Step 3: Setup Ngrok (for public URL) You need an ngrok account (free). Get your auth token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "# Replace 'YOUR_NGROK_TOKEN' with your actual token\n",
        "ngrok_token = \"36xdctnKalIWcD1XC7R6sRPyytN_3NQchoTZTzEK5zfPb8EFy\"  # Get from https://dashboard.ngrok.com/\n",
        "ngrok.set_auth_token(ngrok_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhBcJcDY7_tW",
        "outputId": "9f7f11a6-4435-41da-d719-1f2a2edec149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "🎵 InstruPlay AI is running!\n",
            "============================================================\n",
            "\n",
            "📱 Public URL: https://unjelled-nonunanimously-ronin.ngrok-free.dev\n",
            "\n",
            "✅ Click the URL above to access your app\n",
            "\n",
            "⚠️  Keep this cell running to keep the app alive\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import subprocess                                         #Step 4: Run Streamlit App   This will start the Streamlit server and create a public URL\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any existing streamlit processes\n",
        "!pkill -f streamlit\n",
        "\n",
        "# Start streamlit in background\n",
        "proc = subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port\", \"8501\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "# Wait for streamlit to start\n",
        "time.sleep(15) # Increased sleep time for better initialization\n",
        "\n",
        "# Create public URL\n",
        "tunnel = ngrok.connect(8501)\n",
        "public_url = tunnel.public_url  # Extract the actual public URL string\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print('🎵 InstruPlay AI is running!')\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n📱 Public URL: {public_url}\")\n",
        "print(\"\\n✅ Click the URL above to access your app\")\n",
        "print(\"\\n⚠️  Keep this cell running to keep the app alive\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFBL1UE98FMi",
        "outputId": "62cc945b-759e-488d-97b4-9ee284f70bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "App stopped.\n"
          ]
        }
      ],
      "source": [
        "# Stop streamlit and ngrok                #Step 5: Stop the App (Run when done)\n",
        "!pkill -f streamlit\n",
        "ngrok.kill()\n",
        "print(\"App stopped.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
